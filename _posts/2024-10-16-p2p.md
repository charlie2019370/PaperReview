---
layout: post
title: Prompt-to-Prompt Image Editing with Cross Attention Control
subtitle: ICLR 2023
gh-repo: google/prompt-to-prompt
gh-badge: [star, fork, follow]
thumbnail-img: /assets/img/p2p/thumbnail.png
tags: [Image Editing]
comments: true
mathjax: true
author: Amir Hertz, Ron Mokady, Jay Tenenbaum, Kfir Aberman, Yael Pritch, Daniel Cohen-Or
---

## Abstract

{: .box-note}
Recent large-scale text-driven synthesis models have attracted much attention thanks to their remarkable capabilities of generating highly diverse images that follow given text prompts. Such text-based synthesis methods are particularly appealing to humans who are used to verbally describe their intent. Therefore, it is only natural to extend the text-driven image synthesis to text-driven image editing. Editing is challenging for these generative models, since an innate property of an editing technique is to preserve most of the original image, while in the text-based models, even a small modification of the text prompt often leads to a completely different outcome. State-of-the-art methods mitigate this by requiring the users to provide a spatial mask to localize the edit, hence, ignoring the original structure and content within the masked region. In this paper, we pursue an intuitive prompt-to-prompt editing framework, where the edits are controlled by text only. To this end, we analyze a text-conditioned model in depth and observe that the cross-attention layers are the key to controlling the relation between the spatial layout of the image to each word in the prompt. With this observation, we present several applications which monitor the image synthesis by editing the textual prompt only. This includes localized editing by replacing a word, global editing by adding a specification, and even delicately controlling the extent to which a word is reflected in the image. We present our results over diverse images and prompts, demonstrating high-quality synthesis and fidelity to the edited prompts.

**[Paper (arXiv)](https://arxiv.org/abs/2208.01626)**

## Contents

1. [Introduction](#intro)
2. [Methods](#methods)
3. Applications
4. Conclusions

## Introduction {#intro}

Recent image editing methods are based on Large-scale Language-Image(LLI) models, which masks part of the image and let the model edit the masked region only. This method is slow and inefficient, so a quick and efficient editing method is desired. This paper proposes an effective text-driven image editing method that edits images using pre-trained text-conditioned diffusion models through prompt manipulations. Named **Prompt-to-Prompt(P2P)**, the key idea is to inject cross-attention maps during the diffusion process for editing. Prompt-to-Prompt is able to perform various challenging tasks without model training, fine-tuning, extra data, or optimization.

## Methods {#methods}

Let I be an image generated from a text-guided diffusion model through text prompt P and random seed S. The goal of P2P is to output an edited image \\(I^\*\\) guided only by the edited text prompt \\(P^*\\). What is important is that the appearance and structural information of the generated edited image depends on the relationship between the pixels and the textual embeddings, expressed by cross-attention maps. The overall pipeline of P2P is: 

![pipeline]({{ '/assets/img/p2p/pipeline.png' | relative_url }})
*From: https://www.youtube.com/watch?v=fNd2e56SYZ4*

Here \\(z_t\\) is noisy image and \\(z_0\\) is generated image embeddings. More details will be explained below.

**3.1 Cross-attention in text-conditioned Diffusion Models**

P2P uses Imagen as the backbone model for text-guided synthesis. Each diffusion step t includes predicting noise Îµ from noisy image \\(z_t\\) and text embedding $$\psi(P)$$ using the U-Net network, finally generating \\(I=z_0\\). Then, the spatial features $$\phi(z_t)$$ are linearly projected to the query matrix through the following formula: $$Q=l_Q(\phi(z_t))$$. Textual embedding is also linearly projected to both key and value matrix by $$K=l_k(\psi(P))$$ and $$V=l_v(\psi(P))$$, respectively. After Q, K, V matrices are set, we compute the attention maps using the following formula:
$$M = Softmax(\frac{QK^T}{\sqrt{d}})$$. Here, cell \\(M_{ij}\\) is the weight of the j-th text token on the i-th pixel. Finally, the cross-attention output is computed by $$\hat{\phi}(z_t)=MV.$$

Here's a table:

| Number | Next number | Previous number |
| :------ |:--- | :--- |
| Five | Six | Four |
| Ten | Eleven | Nine |
| Seven | Eight | Six |
| Two | Three | One |

You can use [MathJax](https://www.mathjax.org/) to write LaTeX expressions. For example:
When \\(a \ne 0\\), there are two solutions to \\(ax^2 + bx + c = 0\\) and they are $$x = {-b \pm \sqrt{b^2-4ac} \over 2a}.$$

How about a yummy crepe?

![Crepe](https://beautifuljekyll.com/assets/img/crepe.jpg)

It can also be centered!

![Crepe](https://beautifuljekyll.com/assets/img/crepe.jpg){: .mx-auto.d-block :}

Here's a code chunk:

~~~
var foo = function(x) {
  return(x + 5);
}
foo(3)
~~~

And here is the same code with syntax highlighting:

```javascript
var foo = function(x) {
  return(x + 5);
}
foo(3)
```

And here is the same code yet again but with line numbers:

{% highlight javascript linenos %}
var foo = function(x) {
  return(x + 5);
}
foo(3)
{% endhighlight %}

## Boxes
You can add notification, warning and error boxes like this:

### Notification

{: .box-note}
**Note:** This is a notification box.

### Warning

{: .box-warning}
**Warning:** This is a warning box.

### Error

{: .box-error}
**Error:** This is an error box.

## Local URLs in project sites {#local-urls}

When hosting a *project site* on GitHub Pages (for example, `https://USERNAME.github.io/MyProject`), URLs that begin with `/` and refer to local files may not work correctly due to how the root URL (`/`) is interpreted by GitHub Pages. You can read more about it [in the FAQ](https://beautifuljekyll.com/faq/#links-in-project-page). To demonstrate the issue, the following local image will be broken **if your site is a project site:**

![Crepe]({{ '/assets/img/crepe.jpg' | relative_url }})

If the above image is broken, then you'll need to follow the instructions [in the FAQ](https://beautifuljekyll.com/faq/#links-in-project-page). Here is proof that it can be fixed:

![Crepe]({{ '/assets/img/crepe.jpg' | relative_url }})
